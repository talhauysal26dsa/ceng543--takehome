# Sentiment Analysis with Bidirectional RNNs

## Proje AÃ§Ä±klamasÄ±

Bu proje, **IMDb film yorumlarÄ±** Ã¼zerinde **duygu analizi (sentiment analysis)** yapmak iÃ§in farklÄ± derin Ã¶ÄŸrenme mimarilerini karÅŸÄ±laÅŸtÄ±rÄ±r.

### AmaÃ§

Film yorumlarÄ±nÄ± okuyup "olumlu" veya "olumsuz" diye sÄ±nÄ±flandÄ±ran modeller geliÅŸtirmek ve hangisinin daha iyi Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rmek.

## KullanÄ±lan Teknolojiler

### Modeller:

1. **Bidirectional LSTM (Ã‡ift YÃ¶nlÃ¼ LSTM)**

   - Metni hem soldan saÄŸa, hem saÄŸdan sola okur
   - Uzun baÄŸlamlÄ± bilgiyi hatÄ±rlar
   - Ã–rnek: "Bu film harika DEÄÄ°L" cÃ¼mlesinde "DEÄÄ°L" kelimesinin Ã¶nemini anlar

2. **Bidirectional GRU (Ã‡ift YÃ¶nlÃ¼ GRU)**
   - LSTM'e benzer ama daha basit yapÄ±
   - Daha hÄ±zlÄ± eÄŸitilir
   - Daha az parametre kullanÄ±r

### Embedding (Kelime Temsilleri):

#### A) Static Embeddings (Sabit):

- **GloVe (Global Vectors for Word Representation)**
- Her kelime sabit bir vektÃ¶r ile temsil edilir
- Ã–rnek: "good" kelimesi her zaman aynÄ± [0.2, -0.5, 0.8, ...] vektÃ¶rÃ¼

#### B) Contextual Embeddings (BaÄŸlamsal):

- **BERT (Bidirectional Encoder Representations from Transformers)**
- Kelimelerin anlamÄ± cÃ¼mleye gÃ¶re deÄŸiÅŸir
- Ã–rnek:
  - "Bank is closed" â†’ bank = finans kurumu
  - "River bank is beautiful" â†’ bank = nehir kenarÄ±

## ğŸ“Š DeÄŸerlendirme Metrikleri

1. **Accuracy (DoÄŸruluk):** KaÃ§ tahminin doÄŸru olduÄŸu
2. **Macro F1:** Hem pozitif hem negatif sÄ±nÄ±flar iÃ§in dengeli performans
3. **Convergence Efficiency:** Model ne kadar hÄ±zlÄ± Ã¶ÄŸreniyor

## ğŸ—‚ï¸ Proje YapÄ±sÄ±

```
mt_q1/
â”œâ”€â”€ README.md                          # Bu dosya
â”œâ”€â”€ requirements.txt                   # Gerekli Python paketleri
â”œâ”€â”€ data/                              # Veri dosyalarÄ±
â”‚   â”œâ”€â”€ raw/                           # Ham IMDb verisi
â”‚   â””â”€â”€ processed/                     # Ä°ÅŸlenmiÅŸ veri
â”œâ”€â”€ embeddings/                        # Embedding dosyalarÄ±
â”‚   â”œâ”€â”€ glove/                         # GloVe vektÃ¶rleri
â”‚   â””â”€â”€ cache/                         # BERT cache
â”œâ”€â”€ models/                            # Model tanÄ±mlarÄ±
â”‚   â”œâ”€â”€ lstm_model.py                  # LSTM modeli
â”‚   â”œâ”€â”€ gru_model.py                   # GRU modeli
â”‚   â””â”€â”€ bert_classifier.py             # BERT modeli
â”œâ”€â”€ utils/                             # YardÄ±mcÄ± fonksiyonlar
â”‚   â”œâ”€â”€ data_loader.py                 # Veri yÃ¼kleme
â”‚   â”œâ”€â”€ preprocessing.py               # Ã–n iÅŸleme
â”‚   â””â”€â”€ embedding_loader.py            # Embedding yÃ¼kleme
â”œâ”€â”€ train.py                           # EÄŸitim scripti
â”œâ”€â”€ evaluate.py                        # DeÄŸerlendirme scripti
â”œâ”€â”€ experiments/                       # Deney sonuÃ§larÄ±
â”‚   â”œâ”€â”€ lstm_glove/                    # LSTM + GloVe sonuÃ§larÄ±
â”‚   â”œâ”€â”€ lstm_bert/                     # LSTM + BERT sonuÃ§larÄ±
â”‚   â”œâ”€â”€ gru_glove/                     # GRU + GloVe sonuÃ§larÄ±
â”‚   â””â”€â”€ gru_bert/                      # GRU + BERT sonuÃ§larÄ±
â””â”€â”€ notebooks/                         # Jupyter notebook'lar
    â””â”€â”€ analysis.ipynb                 # SonuÃ§ analizi
```

## ğŸš€ Kurulum

1. Sanal ortam oluÅŸtur:

```bash
python -m venv venv
venv\Scripts\activate  # Windows
```

2. Paketleri yÃ¼kle:

```bash
pip install -r requirements.txt
```

3. IMDb verisini indir:

```bash
python utils/download_data.py
```

4. GloVe embedding'lerini indir:

```bash
python utils/download_glove.py
```

## ğŸ“ KullanÄ±m

### TÃ¼m modelleri eÄŸit:

```bash
python train.py --model all --embedding all
```

### Belirli bir model eÄŸit:

```bash
# LSTM + GloVe
python train.py --model lstm --embedding glove

# GRU + BERT
python train.py --model gru --embedding bert
```

### SonuÃ§larÄ± deÄŸerlendir:

```bash
python evaluate.py --experiment_dir experiments/
```

## ğŸ“ˆ Beklenen SonuÃ§lar

KarÅŸÄ±laÅŸtÄ±racaÄŸÄ±mÄ±z 4 kombinasyon:

1. BiLSTM + GloVe
2. BiLSTM + BERT
3. BiGRU + GloVe
4. BiGRU + BERT

Her biri iÃ§in:

- Accuracy ve F1 skorlarÄ±
- EÄŸitim sÃ¼resi
- Epoch baÅŸÄ±na Ã¶ÄŸrenme hÄ±zÄ±

## ğŸ” Temel Kavramlar

### LSTM vs GRU

- LSTM: 3 kapÄ± (forget, input, output) - daha gÃ¼Ã§lÃ¼ ama yavaÅŸ
- GRU: 2 kapÄ± (reset, update) - daha basit ama hÄ±zlÄ±

### Static vs Contextual Embeddings

- Static (GloVe): Ã–nceden eÄŸitilmiÅŸ, sabit vektÃ¶rler
- Contextual (BERT): CÃ¼mleye gÃ¶re deÄŸiÅŸen, dinamik vektÃ¶rler

### Bidirectional (Ã‡ift YÃ¶nlÃ¼)

- Metni hem ileriye hem geriye doÄŸru okur
- Daha iyi baÄŸlam anlayÄ±ÅŸÄ± saÄŸlar

## ğŸ“š Kaynaklar

- IMDb Dataset: https://ai.stanford.edu/~amaas/data/sentiment/
- GloVe: https://nlp.stanford.edu/projects/glove/
- BERT: https://huggingface.co/bert-base-uncased

## ğŸ‘¨â€ğŸ’» GeliÅŸtirici NotlarÄ±

Bu proje educational amaÃ§lÄ±dÄ±r ve sequence classification task'larÄ± iÃ§in farklÄ± yaklaÅŸÄ±mlarÄ± karÅŸÄ±laÅŸtÄ±rmayÄ± hedefler.
